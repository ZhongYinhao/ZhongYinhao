{"titleNameMap":{"educationList":"教育背景","workExpList":"工作经历","projectList":"项目经历","skillList":"个人技能","awardList":"更多信息","workList":"个人作品","aboutme":"自我介绍"},"avatar":{"hidden":false,"src":"https://i.postimg.cc/XNwhTsFJ/ZYH.png","shape":"square"},"profile":{"name":"钟殷昊","email":"1584553138@qq.com","mobile":"19979165963","github":"","zhihu":"","workExpYear":"","workPlace":"北京","positionTitle":"大模型算法"},"educationList":[{"edu_time":["2020.09.01","2024.06.30"],"school":"北京科技大学","major":"物流工程","academic_degree":"本科","dataIndex":0},{"edu_time":["2024.09.01","至今"],"school":"北京邮电大学","major":"机械工程（硕士）","dataIndex":1}],"awardList":[{"award_info":"蚂蚁近卫军 卓越个人奖","award_time":"2018.09"},{"award_info":"前端练习生 可视化讲师","award_time":"2020.10"},{"award_info":"前端早早聊 分享 “如何构思和开发开箱即用的可视化图表库 G2Plot”","award_time":"2021.07"}],"workExpList":[],"skillList":[{"skill_name":"熟练使用Python语言和Pytorch深度学习框架，熟悉linux系统的使用；","skill_desc":"熟练使用Python语言和Pytorch深度学习框架，熟悉linux系统的使用","skill_level":89,"dataIndex":0},{"skill_name":"熟悉机器学习、深度学习等算法和技术","skill_level":89,"dataIndex":1,"skill_desc":"熟悉机器学习、深度学习等算法和技术"},{"skill_name":"熟悉大模型的高效微调训练(SFT/RLHF等)、模型量化加速和部署优化","skill_desc":"有Llama/Qwen/Deepseek等大模型学习基础，熟悉大模型的高效微调训练(SFT/RLHF等)","skill_level":89,"dataIndex":2}],"projectList":[{"project_name":"基于深度学习的车道线检测","project_role":"","project_time":"2025.03 - 2025.10","project_desc":"设计自动驾驶车道线检测的框架，在提升车道线检测精度的同时保证检测的速度。","project_content":"1. 阅读相关文献并复现论文项目，熟悉基于深度学习的车道线检测的相关原理和流程；\n2. 选择基本的模型框架和添加的几个辅助模块；\n3. 在公开数据集上训练模型并设计实验验证效果。\n","dataIndex":0},{"project_name":"基于演唱会信息的有监督微调","project_role":"","project_time":"2024.10 - 2024.12","project_desc":"使用Easy Dataset和LLaMA Factory微调LLaMA3-8B-Instruct预训练模型，更新2024-2025年世界各地的演唱会信息（时间、地点、特色等）及相关艺人的近况资讯（专辑、活动、生活等）。","project_content":"1. 利用现有大模型RAG在相关网站上爬取近期演唱会和艺人资讯信息，整理成markdown文档；\n2. 利用Easy Dataset将文档分块，提取问题，并调用现有大模型API生成回答，进而构建数据集json格式文件；\n3. 利用LLaMA Factory让预训练模型在构造的数据集上进行LoRA微调训练，评估模型的训练结果；\n4. 合并导出微调后的模型，使用vLLM部署调用。","dataIndex":1},{"project_name":"基于DPO的RLHF微调","project_role":"","project_time":"2025.01 - 2025.03","project_desc":"使用DPO方法微调Qwen2.5-7B-Instruct模型使得模型回答对齐人类喜好。","project_content":"1. 选择人类偏好对数据集dpo_zh_demo和COIG-P (zh)；\n2. 利用LLaMA Factory，使用DPO在构建的数据集上进行LoRA微调训练，评估训练结果。","dataIndex":2}],"workList":[],"aboutme":{"aboutme_desc":"保研至北京邮电大学，现在的研究方向为基于深度学习的自动驾驶车道线检测；\n本科和研究生的数学课程（微积分、最优化等）均取得了90分以上的成绩，有扎实的数学基础；\n英语四级和六级均过600分，有扎实的英语基础和良好的英文论文阅读能力；\n乐于学习新事物，善于沟通和团队协作。\n\n\n    "},"theme":{"color":"#2f5785","tagColor":"#8bc34a"}}